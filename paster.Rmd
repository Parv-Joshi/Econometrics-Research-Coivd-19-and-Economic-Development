---
title: "Paster"
author: 'Parv Joshi [ID: 112169570]'
date: "4/5/2021"
output: word_document
---

```{r}
setwd("C:/Users/Lenovo/Desktop/Spring 2021/ECO 487 459/Data")
library(AER)
library(tidyverse)

detach(data)
data = read.csv("data.csv", sep = ",", header = T)
attach(data)

y = CASES
```


```{r}
x = HCI

linear = lm(y ~ x, data = data)
squared = lm(y ~ x + I(x^2), data = data)
cubed = lm(y ~ x + I(x^2) + I(x^3), data = data)


waldtest(squared, c("I(x^2)"), vcov = vcovHC(cubed, "HC1"))
# Since p-value = 0.8092 > 0.05, Linear model is better

waldtest(cubed, c("I(x^2)", "I(x^3)"), vcov = vcovHC(cubed, "HC1"))
# Since p-value = 0.2042 > 0.05, Linear model is better

p = ggplot(data, aes(x = x, y = y)) + geom_point()
p + stat_smooth(method = "lm", formula = y ~ x, color = "red") + ggtitle("CASES vs. Linear Transformation of HCI")
p + stat_smooth(method = "lm", formula = y ~ log(x), color = "green") + ggtitle("CASES vs. Log Transformation of HCI")

# From graphs, we can conclude that the linear transformation is the best
```

